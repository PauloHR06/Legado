{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;O _Spectral CLustering_, ou agrupamento espectral, é uma das classes de modelos preditivos, onde o processo de clusterização é baseado na teoria de grafos espectrais e em conceitos de álgebra linear. A teoria de grafos espectrais utiliza grafos para representar dados, onde a matriz de similaridade e a matriz laplaciana do grafo são fundamentais para capturar as relações entre os pontos. A matriz de similaridade indica quão próximos ou relacionados os pontos estão, enquanto a matriz laplaciana, que é derivada da similaridade, ajuda a entender a estrutura geral do grafo. Os valores e vetores próprios da matriz laplaciana, obtidos através da álgebra linear, permitem a redução da dimensionalidade dos dados, facilitando a projeção em um espaço onde os clusters são mais visíveis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importings e bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pandas.\n",
    "import numpy as np # numpy.\n",
    "import matplotlib.pyplot as plt  # matplotlib.\n",
    "import seaborn as sns  # seaborn.\n",
    "from sklearn.decomposition import PCA # PCA.\n",
    "from sklearn.cluster import SpectralClustering # spectral clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e visualização do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100820 entries, 0 to 100819\n",
      "Data columns (total 41 columns):\n",
      " #   Column                                           Non-Null Count   Dtype  \n",
      "---  ------                                           --------------   -----  \n",
      " 0   Apolice Sinistro                                 100820 non-null  int64  \n",
      " 1   Codigo Empresa Sinistro                          100820 non-null  int64  \n",
      " 2   Nome Empresa Sinistro                            100820 non-null  object \n",
      " 3   SEGURADO                                         100820 non-null  int64  \n",
      " 4   Codigo Especialidade Sinistro                    100820 non-null  int64  \n",
      " 5   Elegibilidade Sinistro                           100820 non-null  object \n",
      " 6   Sexo Sinistro                                    100820 non-null  object \n",
      " 7   Faixa-Etária Nova Sinistro                       100820 non-null  object \n",
      " 8   Descricao Plano Sinistro                         100820 non-null  object \n",
      " 9   Codigo Servico Sinistro                          100820 non-null  int64  \n",
      " 10  Descricao Servico Sinistro                       100820 non-null  object \n",
      " 11  Tipo Utilização Sinistro                         100820 non-null  object \n",
      " 12  Dt Data Sinistro                                 100820 non-null  object \n",
      " 13  Codigo Prestador                                 100820 non-null  int64  \n",
      " 14  Nome Prestador Sinistro                          100820 non-null  object \n",
      " 15  Valor Pago Sinistro                              100820 non-null  float64\n",
      " 16  Valor Usuario Sinistro                           100820 non-null  int64  \n",
      " 17  Quantidade                                       100820 non-null  int64  \n",
      " 18  No Ano Mes                                       100820 non-null  int64  \n",
      " 19  Codigo Grupo Empresa                             100820 non-null  int64  \n",
      " 20  Nome Grupo Empresa                               100820 non-null  object \n",
      " 21  no-ano-mes_stardardized                          100820 non-null  object \n",
      " 22  faixa-etaria_encoded                             100820 non-null  int64  \n",
      " 23  valor-pago-sinistro_standardized                 100820 non-null  float64\n",
      " 24  quantidade_standardized                          100820 non-null  float64\n",
      " 25  Doença relacionada                               18035 non-null   object \n",
      " 26  Tipo de Serviço                                  100820 non-null  object \n",
      " 27  doenca_relacionadas_encoded                      100820 non-null  int64  \n",
      " 28  tipo_servico_encoded                             100820 non-null  int64  \n",
      " 29  Dia da Semana Sinistro                           100820 non-null  object \n",
      " 30  dia_da_semana_sinistro_encoded                   100820 non-null  int64  \n",
      " 31  Feriado Próximo                                  100820 non-null  bool   \n",
      " 32  elegibilidade_sinistro_encoded                   100820 non-null  int64  \n",
      " 33  sexo_encoded                                     100820 non-null  int64  \n",
      " 34  descricao_plano_sinistro_encoded                 100820 non-null  int64  \n",
      " 35  descricao_servico_sinistro_encoded               100820 non-null  int64  \n",
      " 36  descricao_servico_sinistro_encoded_standardized  100820 non-null  float64\n",
      " 37  doenca_relacionadas_encoded_standardized         100820 non-null  float64\n",
      " 38  tipo_servico_encoded_standardized                100820 non-null  float64\n",
      " 39  dia_da_semana_sinistro_encoded_standardized      100820 non-null  float64\n",
      " 40  faixa-etaria_encoded_standardized                100820 non-null  float64\n",
      "dtypes: bool(1), float64(8), int64(18), object(14)\n",
      "memory usage: 30.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_updated.csv') \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;O _Spectral Clustering_ constrói uma matriz de afinidade que é de ordem quadrática em relação ao número de amostras. Com número grande de amostras, a memória necessária para criar essa matriz pode se tornar muito grande, resultando em erros de alocação de memória. Portanto, utilizamos o método PCA para reduzir a dimensionalidade, antes de clusterizar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\"faixa-etaria_encoded_standardized\", \"valor-pago-sinistro_standardized\", \"quantidade_standardized\", \"doenca_relacionadas_encoded_standardized\"] # features escolhidas.\n",
    "dfNew = df[numeric_columns].sample(frac=0.2)\n",
    "X = dfNew.values\n",
    "\n",
    "# aplicado o PCA para reduzir a dimensionalidade e possibilidade a execução do modelo.\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inteli\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clustering = SpectralClustering(\n",
    "    # hiperparâmetros com Tunning.\n",
    "    n_clusters=4,\n",
    "    n_neighbors=10,                \n",
    "    affinity='nearest_neighbors', \n",
    "    n_init=1  \n",
    ")\n",
    "labels = clustering.fit_predict(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Definir função customizada para calcular e exibir as métricas\n",
    "def custom_clustering_scorer(estimator, X):\n",
    "    labels = estimator.fit_predict(X)\n",
    "    silhouette = silhouette_score(X, labels, metric='euclidean')\n",
    "    davies_bouldin = davies_bouldin_score(X, labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "    \n",
    "    # Exibir as métricas durante a busca\n",
    "    print(f'Silhouette Score: {silhouette}')\n",
    "    print(f'Davies-Bouldin Score: {davies_bouldin}')\n",
    "    print(f'Calinski-Harabasz Score: {calinski_harabasz}')\n",
    "    \n",
    "    # Retornar o silhouette score como métrica para otimização\n",
    "    return silhouette\n",
    "\n",
    "# Definir parâmetros para busca\n",
    "param_distributions = {\n",
    "    'n_clusters': [2],\n",
    "    'linkage': ['ward', 'complete', 'average', 'single'],\n",
    "    'metric': ['euclidean', 'manhattan', 'cosine']\n",
    "}\n",
    "\n",
    "# Scorer customizado para Silhouette\n",
    "silhouette_scorer = make_scorer(silhouette_score, metric='euclidean')\n",
    "\n",
    "# Inicializar o RandomizedSearchCV com AgglomerativeClustering\n",
    "agg_cluster = AgglomerativeClustering()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=agg_cluster,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=3,  \n",
    "    scoring=custom_clustering_scorer,  # Usando a função customizada para calcular as métricas\n",
    "    cv=3,  \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fazer o ajuste com os dados (X_pca é o conjunto de dados PCA transformado)\n",
    "random_search.fit(X_pca)\n",
    "\n",
    "# Resultados da busca\n",
    "print(\"Melhores parâmetros: \", random_search.best_params_)\n",
    "\n",
    "# Avaliar o modelo final nos melhores parâmetros encontrados\n",
    "best_estimator = random_search.best_estimator_\n",
    "labels = best_estimator.fit_predict(X_pca)\n",
    "\n",
    "# Calcular e exibir as métricas para os melhores parâmetros\n",
    "silhouette = silhouette_score(X_pca, labels, metric='euclidean')\n",
    "davies_bouldin = davies_bouldin_score(X_pca, labels)\n",
    "calinski_harabasz = calinski_harabasz_score(X_pca, labels)\n",
    "\n",
    "print(f\"Melhor Silhouette Score: {silhouette}\")\n",
    "print(f\"Melhor Davies-Bouldin Score: {davies_bouldin}\")\n",
    "print(f\"Melhor Calinski-Harabasz Score: {calinski_harabasz}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
